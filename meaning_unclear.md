- [概述](https://radimrehurek.com/data_science_python)

- [jupyter pyspider](https://predictionio.apache.org/datacollection/analytics-ipynb)

- [无趣的时候学习下基本原理](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)

- [牛客面试经](https://www.nowcoder.com/discuss/15168)
> 
  上面这个链接非常重要，讲解了基本的面试套路，下面是摘抄
  
 1、算法提问（推公式）

 2、数据结构提问（写代码）
	手写：快排、堆排、冒泡、归并、二分查找、二叉树遍历、二叉树增删改查
	剑指offer，leecode


3、研究方向、取得成绩 优势

4、项目背景、项目方案、项目成果、项目技术点熟悉

5、常见机器学习原理
	很清楚原理	
	推公式、工程实现（必写代码）
    素材准备:
	  gbdt讲解、rf、xgboost一块讲、输出知识、将面试转化为聊天
	  输出价值观
	  
	突出亮点：最近的paper的进展 技术方面的想法
	  
6、常见解决方案
 - 正负样本不平衡
 
 
 7、常见面试题：
	
  -- 1、svm、lr、gbdt、em 的原理及公式推导
	
  --2、rf、gbdt的区别、xgboost区别（如果问题烂大街问题最好从底层接到）
	
  -- 3、决策树连续值处理方法
  
	-- 4、特征选择方法
	
  -- 5、过拟合解决方法
	
  -- 6、kmeans 原理、有点、改进
	
  -- 7、常见SVM,决策树、贝叶斯的优缺点、适用场景及如何选型
	
  -- 8、svm为啥引入拉格朗日优化方法
	
  -- 9、白话CNN
	
  -- 10、海量item算文本相似度方法
	
  -- 11、梯度下降的优缺点
	
  -- 12、em和kmeans的关系
	
  -- 13、L1和L2的区别及如何解决L1求导困难
	
  -- 14、如何尽量少的样本训练模型同事又能保证模型性能
	
  -- 15、解释word2vec 原理以及哈弗曼树的改进
	
  -- 16、推荐算法的未来看法
	
  -- 17、模型的训练迭代中、怎么评估效果
	
  -- 18、有几个 G 的文本，每行记录了访问 ip 的 log ，如何快速统计 ip 出现次数最高的 10 个 ip ；如果只用 linux 指令又该怎么解决
 
  ....

